{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "from scipy.misc import imread, imsave, imresize\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "patch_size = 64\n",
    "random_state_ = 42\n",
    "\n",
    "n_classes = 4\n",
    "marking_colors = np.array([[14, 209, 69], [255, 127, 39], [136, 0, 27]]) # n_classes - 1\n",
    "class_pixels_density = [0.23823693,  0.00462145,  0.75468649,  0.00245512] # n_classes \n",
    "class_pixels_to_take = np.array([0.5, 2, 0.25, 1]) / sum([0.5, 2, 0.25, 1]) # n_classess predefined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "marking_color = [32, 192, 64]\n",
    "def ans_preprocess(image):\n",
    "    mask = np.ones((image.shape[0], image.shape[1]))\n",
    "    if len(image.shape) == 2:\n",
    "        return np.zeros_like(image)\n",
    "    for i in range(3):\n",
    "        mask = np.logical_and(mask, image[:, :, i] == marking_color[i])\n",
    "    return np.where(mask, 255, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grayscale_measure_mask(image):\n",
    "    return ((image[:, :, 0:1] - image[:, :, 1:2]) ** 2 \n",
    "            + (image[:, :, 1:2] - image[:, :, 2:3]) ** 2\n",
    "            + (image[:, :, 2:3] - image[:, :, 1:2]) ** 2)\n",
    "\n",
    "def ans_preprocess(image):\n",
    "    masks = [grayscale_measure_mask(image)]\n",
    "    for i in range(n_classes - 1):\n",
    "        masks.append(((image - marking_colors[i]) ** 2 ).sum(axis=2, keepdims=True))\n",
    "        \n",
    "    masks = np.concatenate(masks, axis=2)\n",
    "    masks = np.argmin(masks, axis=2).astype(np.uint8)\n",
    "    return masks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def image_augmentation(image):\n",
    "    reflections = [image, \n",
    "                   np.flip(image, 0), \n",
    "                   np.flip(image, 1), \n",
    "                   np.flip(np.flip(image, 1), 0)]\n",
    "    \n",
    "    augmentation = []\n",
    "    for image in reflections:\n",
    "        for k in range(4):\n",
    "            augmentation.append(np.rot90(image, k, (0, 1)))\n",
    "    \n",
    "    return np.array(augmentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_valid_patches(img_shape, patch_size, central_points):\n",
    "    start = central_points - patch_size / 2\n",
    "    end = start + patch_size\n",
    "    \n",
    "    mask = np.logical_and(start >= 0, end < np.array(img_shape))\n",
    "    mask = np.all(mask, axis=-1)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "def get_patches_proportion(Y_dir_name):\n",
    "    for fname in listdir(Y_dir_name):\n",
    "        y = imread(os.path.join(Y_dir_name, fname))\n",
    "        for label in range(n_classes):\n",
    "            class_pixels = (y == label).sum()\n",
    "            max_class_pixels[label] = max(max_class_pixels[label], class_pixels)\n",
    "\n",
    "def extract_patches(img, answer, patch_size=64, average_patches_number=100):\n",
    "    answer = answer.reshape(answer.shape[:2])\n",
    "    \n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    H = img.shape[0]\n",
    "    W = img.shape[1]\n",
    "       \n",
    "    for label in range(n_classes):\n",
    "        pos = np.argwhere(answer == label)\n",
    "        \n",
    "        accepted_patches_mask = get_valid_patches(answer.shape, patch_size, pos)\n",
    "        pos = pos[accepted_patches_mask]\n",
    "        \n",
    "        np.random.shuffle(pos)\n",
    "        \n",
    "        class_pixels_for_image = (1.0 * pos.shape[0] \n",
    "            / (W - 2 * patch_size) \n",
    "            / (H - 2 * patch_size) \n",
    "            / class_pixels_density[label])\n",
    "\n",
    "        n_samples = int(class_pixels_to_take[label] * average_patches_number)\n",
    "        \n",
    "        for i in range(min(n_samples, len(pos))):\n",
    "            start = pos[i] - patch_size / 2\n",
    "            end = start + patch_size\n",
    "            \n",
    "            X.append(img[start[0]:end[0], start[1]:end[1]])\n",
    "            Y.append(answer[start[0]:end[0], start[1]:end[1]])\n",
    "        \n",
    "    return np.array(X), np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def patch_preproces(patches):\n",
    "    patches = patches.astype(np.float32)\n",
    "    patches = patches / 255 - 0.5\n",
    "    patches = patches.transpose(0, 1, 2)\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_for_epoch(X, Y):\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for fname in listdir(X_path):\n",
    "        x = imread(os.path.join(X_path, fname))\n",
    "        y = imread(os.path.join(Y_path, fname))\n",
    "        y = ans_preprocess(y)\n",
    "        \n",
    "        new_x, new_y = extract_patches(x, y, patch_sizes)\n",
    "        X.append(new_X)\n",
    "        Y.append(new_Y)    \n",
    "        \n",
    "    X = np.concatenate(X)\n",
    "    Y = np.concatenate(Y)\n",
    "\n",
    "    X = (X.astype(np.float32) / 255 - 0.5).transpose(0, 3, 1, 2)\n",
    "    Y = Y.reshape(Y.shape[0], -1)\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preproces(patches):\n",
    "    patches = patches.astype(np.float32)\n",
    "    patches = patches / 255 - 0.5\n",
    "    patches = patches.transpose(0, 3, 1, 2)\n",
    "    return patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_data(X, Y):\n",
    "    X = X[:, :, :, np.newaxis]\n",
    "    Y = Y[:, :, :, np.newaxis]\n",
    "    X = preproces(X)\n",
    "    Y = Y.transpose(0, 3, 1, 2).reshape(Y.shape[0], -1)\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_for_epoch(X, Y, image_for_epoch):\n",
    "    X_patches = []\n",
    "    Y_patches = []\n",
    "\n",
    "    idxes = np.random.choice(X.shape[0], image_for_epoch, False)\n",
    "    \n",
    "    for i in tqdm(idxes):\n",
    "        x, y = extract_patches(X[i], Y[i], patch_size)\n",
    "        X_patches.append(x)\n",
    "        Y_patches.append(y)    \n",
    "        \n",
    "    X_patches = np.concatenate(X_patches)\n",
    "    Y_patches = np.concatenate(Y_patches)\n",
    "\n",
    "    X_patches = (X_patches.astype(np.float32) / 255 - 0.5)[:, :, :, np.newaxis].transpose(0, 3, 1, 2)\n",
    "    Y_patches = Y_patches.reshape(Y_patches.shape[0], -1)\n",
    "    \n",
    "    return X_patches, Y_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
